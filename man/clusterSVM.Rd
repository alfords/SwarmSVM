% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/clusterSVM.R
\name{clusterSVM}
\alias{clusterSVM}
\title{Clustered Support Vector Machine}
\usage{
clusterSVM(x, y, cluster.label = NULL, lambda = 1, sparse = TRUE,
  valid.x = NULL, valid.y = NULL, valid.metric = NULL, type = 1,
  cost = 1, epsilon = NULL, svr_eps = NULL, bias = TRUE, wi = NULL,
  verbose = 1, seed = 0, cluster.FUN = stats::kmeans, ...)
}
\arguments{
\item{x}{the nxp training data matrix. Could be a matrix or a sparse matrix object.}

\item{y}{a response vector for prediction tasks with one value for each of the n rows of \code{x}.
For classification, the values correspond to class labels and can be a 1xn matrix,
a simple vector or a factor. For regression, the values correspond to the values to predict,
and can be a 1xn matrix or a simple vector.}

\item{cluster.label}{an 1xn integer vector containing the cluster label of each sample of \code{x}}

\item{lambda}{the weight for the global l2-norm}

\item{sparse}{indicating whether the transformation results in a sparse matrix or not}

\item{valid.x}{the mxp validation data matrix.}

\item{valid.y}{if provided, it will be used to calculate the validation score with \code{valid.metric}}

\item{valid.metric}{the metric function for the validation result. By default it is the accuracy for classification
or RMSE for regression. Customized metric is acceptable.}

\item{type}{the type of the mission for \code{LiblineaR}.}

\item{cost}{cost of constraints violation (default: 1).
Rules the trade-off between regularization and correct classification on data.
It can be seen as the inverse of a regularization constant.
See details in \code{LiblineaR}.}

\item{epsilon}{set tolerance of termination criterion for optimization.
If NULL, the LIBLINEAR defaults are used, which are:}

\item{svr_eps}{set tolerance margin (epsilon) in regression loss function of SVR. Not used for classification methods.}

\item{bias}{if bias is \code{TRUE} (default), instances of data becomes [data; 1].}

\item{wi}{a named vector of weights for the different classes,
used for asymmetric class sizes. Not all factor levels have to be supplied (default weight: 1).
All components have to be named according to the corresponding class label.
Not used in regression mode.}

\item{verbose}{if set to 0, no information is printed.
If set to 1 (default), the running time and validation score (if applicable) will be printed.
If set to 2, the running time ,validation score (if applicable) and the \code{LiblineaR} information will be printed.}

\item{seed}{the random seed. Set it to \code{NULL} to randomize the model.}

\item{cluster.FUN}{set to \code{kmeans} by default. Customized function is acceptable,
as long as the resulting list contains two fields named as \code{cluster} and \code{centers}.}

\item{...}{additional parameters passing to \code{cluster.FUN}.}
}
\description{
Implementation of Gu, Quanquan, and Jiawei Han. "Clustered support vector machines."
}
\examples{
data(iris)
x=iris[,1:4]
y=factor(iris[,5])
train=sample(1:dim(iris)[1],100)

xTrain=x[train,]
xTest=x[-train,]
yTrain=y[train]
yTest=y[-train]

csvm.obj = clusterSVM(x = xTrain, y = yTrain, sparse = FALSE,
    centers = 2, iter.max = 1000,
    valid.x = xTest,valid.y = yTest)
pred = predict.clusterSVM(csvm.obj, xTest)
}

